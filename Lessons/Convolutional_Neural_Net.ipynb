{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Net\n",
    "- **CNN** is basically two dimensional configuration of neural networks\n",
    "- The input of CNN are image (three N by N if it color image and N by N if its black and white image)\n",
    "- The weights are also two dimensional array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN Weights** are known as Kernels or Filter matrix <br>\n",
    "**Stride** is the name for its' filter-matrix/kernals horizontal and vertical movement <br>\n",
    "    (Stride visualization: http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution) <br>\n",
    "**Output Size** = (input_size - filter_size)/stride + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Weights \n",
    "Are known as Kernals or Filter Matricies <br>\n",
    "![CNN Weights](../Images/kernel_image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stride\n",
    "The name for the CNNs' filter-matricies/kernals horizontal and vertical movements <br>\n",
    "\n",
    "Stride Equal To One\n",
    "![Stride Example One](../Images/stride_1.png) <br>\n",
    "Stride Equalt To Two\n",
    "![Stride Example Two](../Images/stride_2.png) <br>\n",
    "\n",
    "\n",
    "- Stride visualization: http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution <br>\n",
    "- **Output Size** = (input_size - filter_size)/stride + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Pooling\n",
    "**Max pooling:** take the maximum element from each window of a certain size <br>\n",
    "![Max Pooling Image](../Images/maxpooling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faltten Layer\n",
    "- After feature extraction that is done by multiple Convolutional layers, **we use flatten layer to add MLP after convolutional layers in order to do classification task**\n",
    "- This one is simple--it's just Keras's version of numpy.reshape. This reshapes n-dimensional arrays to a vector. This is necessary when moving from Conv2D layers, which expect 2-dimensional arrays as inputs, to Dense layers, which expect 1-dimension vectors as inputs. As a concrete example, a Flatten layer given a 28 x 28 array as input would output a vector of the shape (784, 1)\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing a Neural Net (CNN + MLP\n",
    "![Neural Net Process Image](../Images/CNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: Obtain the number of parameters for the following CNN\n",
    "The default strides = (1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**output_size** = (28 - 3)/1 + 1 = 26 <br>\n",
    "**output_size** = (26 - 3)/1 + 1 = 24 <br>\n",
    "**First Conv2D Parameters:** = 32 x 9 + 32 = 320 <br>\n",
    "**Second Conv2D Parameters:** = 64 x 32 x 9 + 64 = 18496 <br>\n",
    "**Flatten Shape:** 12 x 12 x 64 = 9216 <br>\n",
    "**Dense One Parameters** = 9216 x 128 + 128 = 1179776 <br>\n",
    "**Dense Two Parameters** = 128 x 10 + 10 = 1290 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: Explore CNN visualizations and explain what's happening\n",
    "Find Visualization Here: https://www.cs.ryerson.ca/~aharley/vis/conv/flat.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for CNN\n",
    "Suppose we want to feed a 4 by 4 image to a CNN network, how we should reshape the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.        0.        8.790258 ]\n",
      "   [3.603326  6.9580956 2.6464162]]\n",
      "\n",
      "  [[0.        0.        7.820859 ]\n",
      "   [2.005819  3.0757465 6.913532 ]]]]\n",
      "M :\n",
      "[[[0.        0.       ]\n",
      "  [8.790258  3.603326 ]]\n",
      "\n",
      " [[6.9580956 2.6464162]\n",
      "  [0.        0.       ]]\n",
      "\n",
      " [[7.820859  2.005819 ]\n",
      "  [3.0757465 6.913532 ]]]\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 4, 4, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 2)           10        \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 3)           27        \n",
      "=================================================================\n",
      "Total params: 37\n",
      "Trainable params: 37\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "input_img = Input(shape=(4, 4, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(2, (2, 2), activation='relu')(input_img)\n",
    "y = Conv2D(3, (2, 2), activation='relu')(x)\n",
    "model = Model(input_img, y)\n",
    "# cnv_ml_1 = Model(input_img, x)\n",
    "\n",
    "data = np.array([[5, 12, 1, 8], [2, 10, 3, 6], [4, 7, 9, 1], [5, 7, 5, 6]])\n",
    "data = data.reshape(1, 4, 4, 1)\n",
    "print(model.predict(data))\n",
    "print('M :')\n",
    "print(model.predict(data).reshape(3, 2, 2))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 7s 1us/step\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "print(x_train[0].shape)\n",
    "print(x_train[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
